# ---------- Global ----------
ENVIRONMENT=dev
SERVICE_LOG_LEVEL=INFO
REQUEST_LOG_SAMPLE_RATE=1.0

# ---------- Auth ----------
AUTH_DISABLED=true

# ---------- Performance Budgets (ms) ----------
PERF_ASK_P95_MS=3000
PERF_QUERY_P95_MS=4500

# ---------- Arango ----------

# ------------------------------------------------------------------
#  NOTE:
#  * Inside docker-compose the hostname ‘arangodb’ resolves automatically.
#  * When you run any service directly on the host you must point the URL at
#    your host-exposed port instead, e.g.:
#        export ARANGO_URL=http://localhost:8529
#    or use the new CLI flag:
#        python -m ingest.cli --arango-url http://localhost:8529 seed …
# ------------------------------------------------------------------
ARANGO_URL=http://arangodb:8529
ARANGO_DB=batvault
ARANGO_ROOT_USER=root
ARANGO_ROOT_PASSWORD=batvault

# Vector index
ARANGO_VECTOR_INDEX_ENABLED=true
EMBEDDING_DIM=768
VECTOR_METRIC=cosine
FAISS_NLISTS=100

# ---------- Redis ----------
REDIS_URL=redis://redis:6379/0

# ---------- Cache TTLs ----------
CACHE_TTL_RESOLVER=300         # 5 min
CACHE_TTL_EVIDENCE=900         # 15 min
CACHE_TTL_LLM_JSON=120         # 2 min
CACHE_TTL_EXPAND=60            # 1 min
TTL_RESOLVER_CACHE_SEC=300

# ---------- Evidence size budgets ----------
# Legacy (for dashboards only; gating is token-based now)
MAX_PROMPT_BYTES=8192
SELECTOR_TRUNCATION_THRESHOLD=6144
MIN_EVIDENCE_ITEMS=1
GATE_COMPLETION_SHRINK_FACTOR=0.8
GATE_SHRINK_JITTER_PCT=0.15
GATE_MAX_SHRINK_RETRIES=2

# ---------- Feature flags ----------
ENABLE_SELECTOR_MODEL=true
ENABLE_LOAD_SHEDDING=true
ENABLE_GRAPH_EMBEDDINGS=false
ENABLE_ARTIFACT_RETENTION=true
ENABLE_CACHING=true

# ---------- MinIO ----------
MINIO_ENDPOINT=minio:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=batvault-artifacts
MINIO_REGION=us-east-1
MINIO_RETENTION_DAYS=14
MINIO_SECURE=false

# ---------- LLM ----------

# LLM endpoints (canary fully disabled)
CONTROL_MODEL_ENDPOINT=http://vllm-control:8010
CANARY_MODEL_ENDPOINT=http://tgi-canary:8090
CANARY_PCT=0
CANARY_ENABLED=0
CANARY_HEADER_OVERRIDE=x-batvault-canary

# vLLM RAM/VRAM guards – single source of truth
VLLM_GPU_UTIL=0.86              # Fraction of VRAM to allocate (weights + KV budgeting)
VLLM_SWAP_GB=4                  # Allow CPU paging of KV cache (GiB)
VLLM_MAX_MODEL_LEN=2048         # Context upper bound
VLLM_MAX_NUM_SEQS=2             # Concurrency bound
VLLM_MAX_BATCHED_TOKENS=2048    # Prefill/step cap
VLLM_QUANTIZATION=awq           # Matches quantized repo below
PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# off|on
LLM_MODE=on

# Router base for Memory API calls
MEMORY_API_BASE=http://memory_api:8000

# LLM model configuration
# Control model: use quantized 7B so it fits 12 GiB GPUs
VLLM_MODEL_NAME=Qwen/Qwen2-7B-Instruct-AWQ
# Canary/TGI models (canary is disabled; leave as-is or change as needed)
TGI_MODEL_ID=Qwen/Qwen2-7B-Instruct
TGI_CANARY_MODEL_ID=Qwen/Qwen2-7B-Instruct
# Embeddings
TEI_MODEL_NAME=BAAI/bge-base-en-v1.5
ENABLE_EMBEDDINGS=true
EMBEDDINGS_ENDPOINT=http://tei-embed:8085
EMBEDDINGS_DIMS=768
OPENAI_DISABLED=0
HF_TOKEN=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

# ---------- LLM (central, used by gateway) ----------
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=512
# Validator: supporting_ids must be within allowed_ids
CITE_ALL_IDS=false

# ---------- Token-aware budgets (router & selector) ----------
# Total model window; completion cap will be clamped to the remaining room
CONTROL_CONTEXT_WINDOW=2048
# Desired completion; router reduces if prompt is large
CONTROL_COMPLETION_TOKENS=512
# Guard tokens reserve (system/stop overhead)
CONTROL_PROMPT_GUARD_TOKENS=32
# Soft compaction threshold (tokens) before we start trimming optional events
SELECTOR_TRUNCATION_THRESHOLD_TOKENS=1200

# --- TGI memory/concurrency guards (used by tgi-canary service) ---
TGI_CUDA_FRACTION=0.60
TGI_MAX_INPUT_LEN=2048
TGI_MAX_TOTAL_TOKENS=2048
TGI_MAX_PREFILL_TOKENS=2048
TGI_MAX_BATCH_SIZE=1
TGI_MAX_CONCURRENT_REQUESTS=4

# Gateway concurrency guard
LLM_MAX_CONCURRENCY=2

# ---------- Internal Service URLs ----------
MEMORY_API_URL=http://memory_api:8000

# ---------- API rate-limiting ----------
API_RATE_LIMIT_DEFAULT=100/minute   # A-1 – default token-bucket

# ---------- Observability ----------
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317

# ---------- CORS ----------
CORS_ALLOW_ORIGINS=http://localhost:3000,http://localhost:5173
VITE_API_BASE=http://localhost:8080
