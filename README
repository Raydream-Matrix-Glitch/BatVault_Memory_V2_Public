# BatVault — Institutional Memory for a Direction-Driven Org

> **TL;DR** — In an AI world where execution is cheap, advantage comes from **direction**. BatVault is a working prototype of an **institutional memory** system: a queryable, auditable "why-trail" of **events → transitions → decisions**. It shows how to keep speed **coherent** using contracts, deterministic orchestration, and replayable prompts.

---

## What This Repo Is (and Isn't)

**Is:**  
- A **strategic concept** backed by a running prototype (Docker) that demonstrates:  
  - JSON-first contracts & validation  
  - Evidence **bundles** → **prompt envelopes** with **fingerprints** (replayable)  
  - Deterministic **templater fallback** (weak-AI first) with retries/jitter  
  - SSE streaming, structured logs with deterministic IDs, artifacts in MinIO  
  - Graph-backed memory over **ArangoDB** (k=1 rationale neighbors), Redis cache

**Isn't:**  
- A commercial product. It's a **portfolio piece** to show end-to-end thinking (strategy ↔ architecture ↔ code).

---

## 5-Minute Demo (Quick Start)

Prereqs: Docker Desktop (or Compose), ports: 8080/8081/8082/8529/9000/9090/3000 available.

```bash
# 1) Start core services
docker compose up -d arangodb redis minio otel-collector memory_api gateway api_edge

# (Optional) Start open-source LLM & embedding backends for richer summaries
docker compose --profile llm up -d vllm-control tgi-canary tei

# 2) Seed the graph with fixtures
docker compose run --rm ingest python -m ingest.cli seed /app/memory/fixtures --arango-url http://arangodb:8529

# 3) Ask a WHY question (non-stream) — capture headers & JSON
curl -i -X POST http://localhost:8080/v2/ask \
  -H 'content-type: application/json' \
  -d '{"intent":"why_decision","anchor_id":"philips-healthtech-focus-2018","stream":false}' | tee /tmp/ask.json

# 4) Stream the short answer (SSE) to show live tokens
curl -N -X POST 'http://localhost:8080/v2/ask?stream=true' \
  -H 'content-type: application/json' \
  -d '{"intent":"why_decision","anchor_id":"philips-healthtech-focus-2018"}' | tee /tmp/ask.sse

# 5) Trace the request end-to-end (pick request_id from JSON)
jq -r '.meta.request_id' /tmp/ask.json | xargs -I{RID} sh -c 'docker compose logs gateway | grep {RID}'
```

Useful UIs for screenshots:
- **ArangoDB** Graph UI: http://localhost:8529 (view anchor + neighbors)
- **MinIO** (artifacts): http://localhost:9000 (bucket with `evidence_pre/post.json`, `prompt.json`, `validator.json`, `final.json`)
- **Prometheus/Grafana**: http://localhost:9090 / http://localhost:3000

**Anchors you can try:** `philips-healthtech-focus-2018`, `philips-led-lighting-focus-2013`, `panasonic-exit-plasma-2012`

---

## Architecture Overview

### Problem & Solution

In direction-driven organizations, execution is plentiful but coherence over time is scarce. This system captures and operationalizes the why-trail behind decisions — the "events → transitions → decisions" graph — enabling anyone (or any AI agent) to query the rationale, provenance, and adjacent context.

### Architecture (Modular Boundaries)

```mermaid
flowchart LR
  A[Client / CLI] -- SSE / JSON --> B[API Edge]
  B --> C[Gateway]
  C <--> D[Memory API]
  D <--> E[(ArangoDB)]
  C --> F[(MinIO Artifacts)]
  C --> G[Prom/OTel]
  C --> H[(Redis Cache)]
```

**API Edge** (`services/api_edge`) — Front door: auth/headers, CORS, idempotency, basic rate limit, SSE proxying, schema endpoints.

**Gateway** (`services/gateway`) — Orchestrator: intent routing, evidence bundle building (k=1 neighbors), prompt envelope building + fingerprinting, LLM call or deterministic templater fallback, blocking validator, artifact writes (MinIO), structured logging + metrics, load-shedding.

**Memory API** (`services/memory_api`) — Graph + vector facade over ArangoDB: enrich endpoints for normalized objects; expand graph; text resolve.

**Ingest** (`services/ingest`) — JSON-first pipeline (watch → validate → normalize/alias → derive backlinks → persist), Field/Relation Catalogs, ETag batch snapshots for audit and caching.

### Infrastructure

ArangoDB (graph + vector index), Redis (caches), MinIO (artifact store), Prometheus + Grafana (dashboards), OTel Collector (traces/metrics); everything wired via `docker-compose.yml`.

### Core Mapping

- **Institutional memory** = queryable "why" trail: events, transitions, decisions, with provenance and constraints
- **Orchestration > execution**: Gateway composes Evidence Bundles from Memory API, builds signed/fingerprinted Prompt Envelope, ensures outputs obey JSON contracts
- **Traceability/auditability**: Every step logs structured B5-style JSON with `request_id`, `snapshot_etag`, `prompt_fingerprint`, plus metrics; artifacts stored in MinIO with lifecycle retention
- **Direction telemetry**: Normalized and cross-linked decisions enable directional queries ("why did we pivot?", "where are contradictions vs OKRs?") streamed via SSE

### Control Loop

1) **Evidence Builder** pulls the anchor decision + k=1 neighbors (events, transitions; WHY intent excludes neighbor decisions).  
2) **Selector** enforces byte budgets → deterministic context.  
3) **Prompt Envelope** with **bundle+prompt fingerprints** + policy/constraint IDs.  
4) **LLM Router** (control/canary) → **Templater Fallback** when needed.  
5) **Validator** repairs → **Artifacts** stored; SSE streams `short_answer`.  
6) Every response carries `x-request-id` and `x-snapshot-etag` for audit.

### Core Concepts

- **Decision/Event/Transition**: graph ontology for "why-trail"
- **Snapshot ETag**: content hash of the graph at ingest; every answer links to a snapshot
- **Evidence Bundle**: the minimal, deterministic context for a question
- **Prompt Envelope**: canonical JSON with fingerprints → **replayable**
- **Deterministic Fallback**: guaranteed, non-hallucinated answer built from evidence only
- **Validator & Contracts**: JSON-first schemas + repairs; `supporting_ids ⊆ allowed_ids`
- **Artifacts**: `evidence_pre/post.json`, `prompt.json`, `llm_raw.json`, `validator.json`, `final.json`

### Functional Features

1. **JSON-first contracts & validation**: Pydantic models in `packages/core_models`; blocking validator in `packages/core_validator` with canonical `allowed_ids` and invariant enforcement

2. **Prompt envelope fingerprinting & replay**: Deterministic canonical JSON + sha256 fingerprints for prompts ensure exact reconstruction of what hit the model

3. **Deterministic fallback + retries**: LLM produces only `answer.short_answer` JSON (temp=0, low tokens); templater composes deterministic answers from evidence on failure; retries capped at 2

4. **Evidence bundle builder**: Gateway resolves anchor decision, expands k=1 neighbors via Memory API, merges events + transitions, computes canonical `allowed_ids`

5. **SSE streaming**: API Edge exposes `/v2/ask` and `/v2/query` that stream tokens to browser; Gateway provides `stream_chunks`

6. **Structured logging & metrics**: B5-style JSON logs with `request_id`, `snapshot_etag`, fingerprints, model IDs; Prometheus metrics + OTel export hooks

7. **Idempotency & determinism**: Keys derived from (path, query, body) or header; consistent `request_id` generation

8. **Artifact store with retention**: Gateway ensures MinIO bucket + lifecycle policy, writes artifacts (`evidence_pre.json`, `prompt.json`, `llm_raw.json`, `validator.json`, `final.json`)

9. **Memory API normalization**: Enrich endpoints return normalized envelopes; `expand_candidates` runs AQL k=1 traversals; vector search via ArangoSearch/TEI embed

10. **Ingest V2 pipeline**: Watch → Validate (STRICT) → Normalize/Alias → Derive backlinks → Persist; Field/Relation catalogs surface available aliases and edges; `snapshot_etag` propagated through logs and artifacts

### Primary Flows

**A) `/v2/ask` (decision-reference path)**
1. API Edge accepts JSON (`{intent, decision_ref}`), computes `idempotency_key`, forwards to Gateway
2. Gateway resolves anchor, expands neighbors, builds Evidence Bundle with canonical `allowed_ids`
3. Builds Prompt Envelope (+ fingerprint/policy), logs fingerprints
4. LLM call (if `llm_mode!=off`; retries ≤2) → else templater fallback
5. Validator normalizes response; artifacts written to MinIO; SSE `short_answer` stream
6. API Edge streams SSE to client; exposes `/v2/schema/*` proxying catalogs

**B) `/v2/query` (natural-language path)**
Intent router determines intent and Memory API function calls (`search_similar`, `get_graph_neighbors`), merges candidate IDs into evidence, then same as `/v2/ask`.

### Data Model

- **Decision**: `{id, option, rationale, timestamp, decision_maker?, tags[], supported_by[], based_on[], transitions[]}`
- **Event**: `{id, summary, description?, timestamp, tags[], led_to[], snippet?}`
- **Transition**: `{id, from, to, relation (causal|alternative|chain_next), reason?, timestamp, tags[]}`
- **Evidence Bundle**: `{anchor, events[], transitions{preceding|succeeding}, allowed_ids[]}`
- **Answer**: `{short_answer ≤320, supporting_ids ⊆ allowed_ids, rationale_note?}`
- **Response**: `{intent, evidence, answer, completeness_flags, meta{policy_id, prompt_id, retries, latency_ms, prompt_fingerprint, snapshot_etag, fallback_used}}`

### API Quick Reference

- `POST /v2/ask` → WHY decision (anchor_id required). Supports `stream=true` (SSE).  
- `POST /v2/query` → Natural language; intent router + helper functions (WIP).  
- Memory API:  
  - `GET /api/enrich/decision/{id}`  
  - `POST /api/graph/expand_candidates` (k=1 neighbors)  
  - `POST /api/resolve/text` (BM25; optional vectors)  

**Headers you'll see:** `x-request-id`, `x-snapshot-etag`, `x-model`, `x-canary`

### Quality Assessment

* **Modular boundaries:** Clean separation (API app / evidence / selector / prompt / llm / templater) ✅
* **JSON-first:** Pydantic models in `core_models`, validator in `core_validator` with canonical allowed-IDs and repairs ✅
* **Structured logging + deterministic IDs:** `request_id`, `snapshot_etag`, fingerprints, `last_call` surfaced ✅
* **Prompt envelope fingerprinting & replay:** Built in; exposed in OTEL ✅
* **Retries/jitter + deterministic fallbacks:** In `llm_router` and `templater` ✅
* **Async I/O & cache-optimized:** httpx async, Redis; freshness via ETag check ✅
* **Tests:** Rich suite under `tests/` for SSE, gateway metrics, audit metadata ✅
* **Dockerized & K8s-ready:** Compose solid; Helm/kustomize next step (appendix) ➕
* **Pluggable CPU-fast ML:** Router targets vLLM/TGI; adapters stubbed for clean swap ✅
* **SSE & audit drawer:** `sse.py` shaped correctly; Audit Drawer gets context from `resp.meta` + headers ✅

## Shared Modules

### What the Shared Packages Do

* **`core_utils`** – Little building blocks
   * **IDs & slugs** (`ids.py`): Deterministic `request_id`, idempotency keys, safe slugging for IDs/tags
   * **Fingerprints** (`fingerprints.py`): Stable, canonical JSON + `sha256:` fingerprints for prompts/bundles
   * **Timeouts** (`async_timeout.py`): Per-stage budget wrapper (so calls can't hang forever)
   * **Health wiring** (`health.py`): Drop-in `/healthz` & `/readyz` for any FastAPI service
   * **Snapshot** (`snapshot.py`): Content-addressable **ETag** for batches/snapshots
   * **Uvicorn runner** (`uvicorn_entry.py`): Consistent boot settings

* **`core_logging`** – Structured logging primitives
   * Global **snapshot-etag filter**, so every log line can carry current `snapshot_etag`
   * `get_logger`, `log_stage` (with decorator & context manager), and `trace_span` for consistent, structured logs

* **`core_metrics`** – Simple counters/gauges/histograms
   * Emits **Prometheus** metrics and **OTel** when configured, no-ops cleanly in dev/tests
   * Tiny helpers: `counter`, `histogram`, `histogram_ms`, `gauge`

* **`core_models`** – JSON-first contracts
   * Pydantic models for anchor/evidence/answer/response; validators for tags/snippets, etc.

* **`core_validator`** – Contract enforcement & gentle repair
   * Normalizes/repairs responses (e.g., canonical `allowed_ids`; safe `supporting_ids` subset)

* **`core_storage`** – Backing stores
   * **Arango** accessors (nodes/edges upsert, prune stale, set snapshot ETag, text search, vector toggles)
   * **MinIO** helpers (ensure bucket + lifecycle; upload snapshot artifacts)

* **`core_config`** – Settings & constants
   * Central timeouts, byte budgets, cache TTLs; single `Settings` model for all services

### Strategic Impact

**Why this matters for your "direction-driven org" thesis:**
* **Coherence at speed**: Same **IDs, ETags, and fingerprints** appear in logs, headers, and artifacts — you can trace "what" and "why" end-to-end
* **Explainability**: `log_stage` + `trace_span` standardize how we tell the "story" of a request (inputs, choices, budgets, outputs)
* **Governance without friction**: Metrics + structured logs give execs telemetry on direction (not just throughput), without slowing teams down

**Strategic impact of these tweaks:**
* **Same compact IDs** show up across logs and dashboards → faster triage and storytelling in reviews
* **Timeouts** become visible as count per stage → easy to spot where orchestration needs more budget or caching
* **Latency** publishing gets dead simple → consistent tiles across Gateway/Memory/Ingest without custom code

---

## API Edge — What It Does

**Purpose:** Be the safe front door. Accepts client requests, attaches **request ID**, applies **CORS**, handles **auth (stub)**, adds **structured logs/metrics**, and **proxies** to the Gateway.

### Key Responsibilities

- **Streaming preserved**: If client asks for Server-Sent Events (`stream=true`), relays Gateway's stream directly
- **Headers you care about**: Adds `x-request-id` on regular JSON responses and mirrors Gateway's `x-snapshot-etag` (freshness tag)
- **Rate limiting**: Tiny rate limiter protects front door without complicating teams' workflows — speed with guardrails

### Implementation

*Key files:* `services/api_edge/src/api_edge/app.py`, `rate_limit.py`

### Strategic Mapping

- **Coherence at speed**: Consistent `x-request-id` across services lets you follow decision-answer end-to-end
- **Explainability**: Mirroring `x-snapshot-etag` ties answers to specific **graph snapshot** (the "why" context)
- **Resilience & fairness**: Rate limiting protects front door while maintaining workflow speed

### Quick Alignment Check (Strategy)

- **Direction is observable**: Every client response (stream or JSON) carries `x-request-id` + `x-snapshot-etag`, so you can stitch the "why-trail" from UI → Edge → Gateway → Memory
- **Orchestration is visible**: `x-model`/`x-canary` headers expose model routing choices — **governance-friendly** and helps prove the system's behavior
- **Guardrails without friction**: Small rate limiter keeps front door responsive under burst without adding process overhead

---

## Ingest — What It Does

**Goal:** Turn raw JSON files (decisions, events, transitions) into clean, consistent **graph snapshot** that the rest of the system can trust.

### How It Works (Step by Step)

1. **Watch for changes**: Small watcher computes **snapshot ETag** (hash of all files). When anything changes, emits `new_snapshot` log and updates in-memory ETag
   - *File:* `services/ingest/src/ingest/watcher.py`

2. **Load & alias**: CLI (`ingest seed <dir>`) recurses folder, loads all JSON, **maps different field names** (e.g., `title` → `option`)
   - *File:* `services/ingest/src/ingest/cli.py`

3. **Validate**: Every document checked against **JSON Schemas** (decision/event/transition). Bad files rejected with precise errors
   - *Files:* `services/ingest/src/ingest/schemas/json_v2/*.schema.json`

4. **Normalize & enrich**: IDs slugged, timestamps normalized, **snippets** synthesized, tags cleaned
   - *Files:* `pipeline/normalize.py`, `pipeline/snippet_enricher.py`

5. **Backlinks (reciprocity)**: If decision says it's **based_on** another, ensure prior decision's **transitions** reflect that link — consistency both ways
   - *File:* `packages/link_utils/.../derive_links.py`

6. **Compute snapshot & persist**: Recompute **snapshot ETag**, then:
   - **Upsert** nodes & edges to Arango (idempotent)
   - **Set** graph's snapshot ETag
   - **Upload** whole snapshot to MinIO (compressed), making it **addressable** by ETag
   - **Prune** stale docs (anything not in new snapshot)
   - **Publish catalogs** (fields & relations)
   - *Files:* `pipeline/graph_upsert.py`, `core_storage/arangodb.py`, `ingest/cli.py`, `ingest/catalog/field_catalog.py`

### Outputs

Fully normalized graph + **content-addressed snapshot** (`<etag>.json.gz`) + structured logs/metrics for trust and replay capability.

### Strategic Mapping

| Need | What Ingest Provides |
|---|---|
| **Coherence at speed** | One canonical graph snapshot (ETag) that every service references — no drifting copies |
| **Explainable "why-trail"** | Clean relationships between events ↔ transitions ↔ decisions, with **backlinks** and **snippets** to make context scannable |
| **Auditability** | Content-addressed archives in MinIO, plus structured logs for every step (validation, normalization, pruning) |
| **Balance core & edges** | **Field/Relation Catalogs** make core ontology explicit while allowing team-level aliasing upstream (mapped into core form here) |

---

## Memory API — What It Does

**Purpose:** Turns your organization's raw nodes/edges into clean, fast answers the Gateway can use.

### Three Big Jobs

1. **Explain a node** (enrich): Return consistent shape for **Decision**, **Event**, or **Transition** — always with same fields, so downstream systems don't guess
   - Endpoints: `/api/enrich/decision/{id}`, `/api/enrich/event/{id}`, `/api/enrich/transition/{id}`

2. **Find nearby context** (neighbors): Given a node, return most relevant **events and transitions** around it (k-hop = 1 by default)
   - Endpoint: `/api/graph/expand_candidates`

3. **Resolve text to nodes** (search): Turn natural-language query into best-matching nodes — BM25 today, with **vector search** toggleable
   - Endpoint: `/api/resolve/text`; vectors via `embeddings_client.py` when enabled

### Key Features

- **Freshness & speed**: Every response carries/sets **snapshot ETag** (freshness tag) with fast timeouts and graceful fallbacks (never blocks Gateway)
- **Auditability**: Adds structured logs, sets Prom/OTEL metrics, includes ETag as header so Gateway can tie answers to specific data snapshot

### Strategic Mapping

- **Make direction observable**: Returns normalized, predictable shapes Gateway can reason about (evidence bundles feeding the why-trail)
- **Keep answers coherent at speed**: ETags + timeouts + fallbacks mean fast answers that are traceable and replayable
- **Balance core + edges**: Schema/relations catalogs let teams extend locally while keeping stable core ontology — Memory API remains single source of truth for graph queries

### Implementation

- `app.py` — FastAPI app; health, metrics, catalogs, **enrich**, **expand_candidates**, **resolve_text**
- `embeddings_client.py` — Optional vector search (Text Embeddings Inference) with retries and structured logs
- `packages/core_storage/arangodb.py` — Arango access: ensure collections/graph, **neighbors (k=1)**, **text search**, optional **vector index**
- `packages/core_utils` / `core_logging` — Health hooks, IDs, structured logs, ETags, traces

### Small Improvements (Surgical, Value-Dense)

1. **Put snapshot ETag directly in body for `/api/resolve/text`**: Header already carries it, but adding in `meta` makes frontends/audit drawers simpler
2. **Clamp & echo `k` in neighbors + one finished log**: Prevent accidental huge traversals, add single "expand completed" log with neighbor count (quick observability win)

---

## Gateway — Role & Responsibilities

The orchestrator that turns user questions (e.g., "Why did we pivot from X to Y?") into deterministic, auditable pipelines.

### Execution Flow

**0) Inbound API & routing** (`services/gateway/src/gateway/app.py`)
- Main entrypoint: `POST /ask` accepting `AskIn` (Pydantic) with `intent`, `anchor_id`, optional `functions`, `stream` & `include_event` flags
- If functions present, calls intent router (`intent_router.py`) returning `routing_info` with `function_calls`, confidence/model id, and helper results
- Merges helper results (`search_similar`, `get_graph_neighbors`) into evidence before building prompt

**1) Evidence gathering & cache** (`evidence.py → EvidenceBuilder`)
- Redis-backed two-level cache: pointer key `evidence:{anchor_id}:latest` → content key `evidence:sha256(<decision,intent,…>)`
- Freshness: checks Memory-API ETag (`_snapshot_etag`) before using cached bundle via fast HEAD/GET (`x-cache-etag-check`)
- Build path: `GET enrich/decision/{id}` + optionally expand neighbors (k=1) via `graph/expand_candidates`
- Everything wrapped in trace spans with `bundle_size_bytes` recorded

**2) Selector & byte-budget guarantees** (`selector.py`)
- Computes size via `bundle_size_bytes()`
- If over soft threshold → rank & drop least important items by recency and semantic similarity (Jaccard against anchor rationale)
- Hard ceiling `MAX_PROMPT_BYTES`: clips long fields, then prunes items as last resort
- Emits structured log `selector_complete` and Prom metrics (`selector_ms`, `final_evidence_count`, `bundle_size_bytes`, dropped ID counters)

**3) Prompt envelope & fingerprints** (`prompt_envelope.py`)
- Assembles canonical JSON, computes `bundle_fingerprint` & `prompt_fingerprint` (sha256-prefixed) using `core_utils.fingerprints.canonical_json`
- Writes fingerprints into envelope, sets OTEL span attributes for correlation
- Includes `policy_id`, `prompt_id`, constraints (`max_tokens`), `prompt_version` (`why_v1` default)

**4) LLM call with canary + fallback** (`llm_router.py`)
- Stable canary routing per `request_id`; override via header
- Targets: `CONTROL_MODEL_ENDPOINT` (vLLM control) vs `CANARY_MODEL_ENDPOINT` (TGI canary)
- Retries with jitter (≤100ms); Prom metrics for latency (`gateway_llm_latency_ms`) and requests; stores `last_call` (model, canary, attempt, latency)
- `llm_client.summarise_json` returns JSON string for `short_answer` or deterministic stub on failure
- **Deterministic templater fallback** (`templater.py`): builds `short_answer` from evidence only (no hallucinations); enforces subset rules for `supporting_ids`; length ≤320

**5) Contract validation & response** (`builder.py`)
- Captures pre/post evidence, plan, envelope, raw LLM, validator report, response — all for MinIO archival
- Canonical `allowed_ids` recomputed via core validator; repairs and structured errors collected
- Response: `WhyDecisionResponse {intent, evidence, answer, completeness_flags, meta}`
- Meta includes fingerprints, policy/prompt IDs, selector model id, latency, retries count, `load_shed` flag
- `app.py` enriches meta with intent router info and handles SSE streaming (`sse.py`) including headers (`x-model`, `x-canary`, `x-snapshot-etag`)

### Strategic Alignment

| Strategic Need | Gateway Delivery |
|---|---|
| **Direction over capability** | Selector trims noise; router chooses helpers; prompt envelope fixes constraints; validator enforces contracts — system decides what matters before any model runs |
| **Institutional memory (why-trail)** | Evidence builder binds events ↔ transitions ↔ decisions with ETags; artifacts persisted; fingerprints enable exact replay |
| **Auditability & trust** | Every step logs deterministic IDs (`request_id`, `snapshot_etag`, fingerprints); Prom/OTEL expose timing and behaviors; SSE includes model/canary headers |
| **Operational integration** | Async I/O (httpx), Redis cache, MinIO artifacts, Prom/OTEL; deterministic fallback for graceful degradation |
| **Balance autonomy vs coherence** | Router lets teams query in their language (functions/search), while core ontology & validator keep evidence coherent |

---

## Platform Extensibility — Question-Aware Intents

### Current WHY Intent (k=1, decisions excluded)

The system already implements optimal behavior for "Why did we do X?" queries:
- k=1 neighbors collected via Memory API
- Neighbor decisions are dropped; only events and transitions kept for evidence bundle
- (See `services/gateway/src/gateway/evidence.py`: decision-type neighbors are continued/ignored)

This keeps rationale tight and avoids dragging in follow-up decision nodes.

### How Hard Is It to Extend to Be "Question-Aware"?

**Short answer:** Very doable with current modularity. You already have the right hooks:
- Request includes an `intent`
- `EvidenceBuilder` has parameters (`include_neighbors`, `intent`, `scope="k1"`) and already treats neighbors differently
- Prompt envelope accepts policy/prompt/constraint overrides
- Deterministic templater fallback and validator are in place

### Minimal Enablement (3 small changes)

**1) Pass the intent from request into EvidenceBuilder**

*File: `services/gateway/src/gateway/app.py`*
```diff
- ev = await _evidence_builder.build(anchor["id"], include_neighbors=include_neighbors)
+ ev = await _evidence_builder.build(anchor["id"], include_neighbors=include_neighbors, intent=req.intent or "why_decision")
```

**2) Only skip neighbor decisions for WHY intent**

*File: `services/gateway/src/gateway/evidence.py`*
```diff
- if ntype == "decision":
+ if intent == "why_decision" and ntype == "decision":
    continue
```

**3) Feed intent into prompt envelope (optional)**
```python
envelope = build_prompt_envelope(
    question=req.question or "...",
    evidence=ev.model_dump(mode="json"),
    intent=req.intent,
    policy_name={"why_decision":"why_v1","status_decision":"status_v1"}.get(req.intent,"why_v1"),
    constraint_schema={"why_decision":"WhyDecisionAnswer@1","status_decision":"StatusAnswer@1"}.get(req.intent,"WhyDecisionAnswer@1"),
)
```

**Result:** For new intents (e.g., "status_decision", "what_changed"), you can include decision neighbors without changing other logic.

### "Cutting-Edge" Extensions (How You'd Add Them Cleanly)

**Intent registry (plug-and-play)**
- Define `IntentSpec` per intent: k, include_decisions Yes/No, helper functions, policy/prompt IDs, constraint schema, max tokens
- Add `gateway/intent_specs.py` and call from `app.py` before building evidence
- *Impact: Low* — avoids `if intent ==` everywhere; makes adding intents a data change

**Conflict/coverage intents**
- `intent="find_conflicts"`: reuse graph expansion, templater highlights contradicting decisions (simple AQL)
- `intent="coverage_of_objective"`: count/tag decisions linked to OKR; templater explains gaps
- *Impact: Moderate* — mostly Memory-API query + templater

**Temporal "what changed"**
- Pull k=1 neighbors at two snapshots (ETag A vs ETag B); templater/LLM summarizes deltas
- *Impact: Low* — you already store ETags and snapshots

**Auto-rationale extraction**
- Ingest adds pass to lift rationale fragments from Slack/Jira messages (regex/heuristics), marks as candidate evidence
- *Impact: Moderate* — opt-in, boosts capture with low friction

**Policy checks (governance)**
- Gateway emits warnings or "needs info" when decision lacks owner/tradeoffs
- *Impact: Very low* — validator + templater can already emit completeness flags

**Prompt/constraint versioning**
- Registry of policy_id/prompt_id per intent, pinned in responses; fingerprint envelopes add semantics
- *Impact: Very low* — mostly config

**Evaluation harness (golden tests)**
- For each intent, N golden cases with fixed evidence → expected short_answer/supporting_ids
- *Impact: Low* — you already have strong test skeleton

### Complexity Summary

- **Low complexity**: Pass intent to builder; include decision neighbors by intent; prompt registry; policy checks; telemetry already instrumented
- **Moderate complexity**: New Memory-API queries for conflict/coverage; delta-by-ETag; auto-rationale extraction  
- **Higher complexity (optional)**: Rich FE audit drawer + live dashboards (demo via screenshots first)

---

## Why It Matters (For Recruiters)

- AI makes execution abundant; **direction** is the bottleneck
- This repo shows how to make direction **observable** and **auditable**
- It balances **core coherence** (ontology, contracts) with **edge autonomy** (aliasing, light capture)

---

## Observability (How to "See" the System)

- **Logs** include: `request_id`, `snapshot_etag`, **fingerprints**, `llm_fallback_used`, `validator_repaired`, `selector_truncated`
- **Metrics**: request/latency histograms, `gateway_llm_fallback_total`, stage timeouts