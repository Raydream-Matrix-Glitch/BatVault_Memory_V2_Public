{
  "id": "acme-corp-adopt-gpu-platform-2023",
  "option": "Adopt an internal GPU platform and model gateway for AI features",
  "rationale": "Secure GPU capacity, enforce safety/latency controls, and reduce per-inference cost via utilization and caching.",
  "timestamp": "2023-03-30T16:00:00Z",
  "decision_maker": "CTO",
  "tags": ["ai_platform", "latency", "cost_optimization"],
  "supported_by": [
    "acme-e-gpu-shortages-2022-2023",
    "acme-e-latency-slo-misses-2023q1"
  ],
  "based_on": ["acme-corp-unify-cloud-platform-2022"],
  "transitions": [],
  "domain": "acme/corporate",
  "importance": 0.87,
  "sensitivity": "high",
  "namespaces": ["internal", "confidential"],
  "roles_allowed": ["director", "exec"],
  "x-extra": {
    "kpis": [
      {
        "name": "Inference cost",
        "unit": "USD/1k tokens",
        "baseline": 0.90,
        "target": 0.35
      },
      {
        "name": "p95 latency",
        "unit": "ms",
        "baseline": 850,
        "target": 300
      },
      {
        "name": "GPU utilization",
        "unit": "%",
        "baseline": 28,
        "target": 65
      }
    ],
    "kpi_tracking_id": "KPI-AI-2023-03"
  }
}